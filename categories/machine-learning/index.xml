<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning on Inno Jia</title>
    <link>https://kobehub.github.io/categories/machine-learning/</link>
    <description>Recent content in Machine Learning on Inno Jia</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Mon, 14 Jan 2019 20:23:39 +0800</lastBuildDate>
    
	<atom:link href="https://kobehub.github.io/categories/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>[Review] Neural Networks</title>
      <link>https://kobehub.github.io/posts/review-neural-networks/</link>
      <pubDate>Mon, 14 Jan 2019 20:23:39 +0800</pubDate>
      
      <guid>https://kobehub.github.io/posts/review-neural-networks/</guid>
      <description>神经网络与深度学习 1. Artificial Neural Networks 1.1 M-P Neuron Model 由生物神经元的启发，McCulloch and Pitts在1943年提出了MP神经元模型。神经元模型是一个包含输入，输出与计算功能的模型。
输入可以类比为神经元的树突，而输出可以类比为神经元的轴突，计算则可以类比为细胞核。神经元接收来自n个其他神经元传递过来的输入信号，这些输入信号通过带权重的连接进行传递，神经元接收到的总输入值将与神经元的阈值进行比较，然后通过激活函数的处理产生神经元的输出。这是仅有一个神经元的模型。
激活函数：
阶跃函数，输出值大于0则为1，否则为0 $$ sgn(x)= \begin{cases} 1, &amp;amp; x \geq 0; \\ 0, &amp;amp; x &amp;lt; 0; \end{cases} \\y= \begin{cases} 1, &amp;amp; \sum_{i=1}^{n}w_ix_i-b \geq 0; \\0, &amp;amp; otherwise; \end{cases} $$
1.2 Perceptron 第一个可以根据输入样本学习权重的模型，是首个可以学习的人工神经网络。The Perceptron was introduced in 1958 by Frank Rosenblatt.
该模型有两个层次。分别是输入层和输出层。输入层里的“输入单元”只负责传输数据，不做计算。输出层里的“输出单元”则需要对前面一层的输入进行计算我们把需要计算的层次称之为“计算层”，并把拥有一个计算层的网络称之为“单层神经网络”。单层感知机只可以处理线性可分的数据。
多层感知机（MLP）
多层感知机具有一个或者多个隐含层，不同的层之间神经元是全连接的。这是一个典型的前馈网络（Feedforward ）,在该网络中，信息只朝着一个方向移动。
深度学习之父杰弗里·辛顿（Geoffrey Hinton），其在1986年发明了适用于多层感知器（MLP）的BP算法（反向传播算法），并采用Sigmoid激活函数进行非线性映射，有效解决了非线性分类和学习的问题。
Activate Function:
Sigmoid 函数，与用于分类问题的线性回归中使用的联系函数相同。
1.3 LeNet 1989 年。 Yann LeCun（乐困）利用反向传播的思想发明了卷积神经网络-LeNet，并将其用于数字识别，且取得了较好的成绩。BP算法被指出存在梯度消失问题，即在误差梯度反向传递的过程中，误差梯度传到前层时几乎为0，因此无法对前层进行有效的学习。</description>
    </item>
    
    <item>
      <title>[Review] Regression</title>
      <link>https://kobehub.github.io/posts/review-regression/</link>
      <pubDate>Mon, 14 Jan 2019 15:35:50 +0800</pubDate>
      
      <guid>https://kobehub.github.io/posts/review-regression/</guid>
      <description>线性回归 1. 回归模型 回归任务主要是处理连续值的模型。回归学习是用来估计输入值和输出值之间的关系，建立输入值和输出值之间的数学模型，当再来一个新样本时，可以预测新样本的输出值。回归是一个有监督的学习过程，在建立输入值和输出值之间的数学模型时，需要有训练集，在预测的时候需要一些先验知识。
典型例子：房价的估计
分类 1. 按照输入值的数量
 单元回归，输入的特征值只有一个 多元回归，输入多个特征值  2. 输入与输出的关系
 线性回归 非线性回归  基本模型： $$ f(x_i) = wx_i + b $$ 最常用的性能度量是均方误差，可以试图通过令均方误差最小化求得参数。
2.最小二乘法 2.1 单元线性回归 对于只有一维特征的线性回归，可以直接使用均方误差作为损失函数。同时，对于$w, b$求偏导。令其等于0，即可以求出模型的两个参数。
2.2 多元线性回归 更一般的情形是对于一个数据集D由d个属性进行描述，所以输入的特征是d维特征，此时试图学得的模型可以表示为： $$ f(x_i) = w^T x_i + b $$ 可以把参数$w^T ,b吸收入向量的形式 \hat{w} = (w^T; b)$,同时把数据集D表示为一个m * (d+1) 的矩阵形式，其中每一行代表一个样本，每一列代表一个属性，同时把标记也写作向量形式 m * 1
优化目标： $$ \hat{w} = argmin _{ \hat{w} } (y-X \hat {w})^T (y - X \hat {w}) \\ E _{ \hat {w}} = (y-X \hat {w}) ^T(y - X \hat {w}) $$ 求偏导： $$ \frac{ \partial E}{\partial \hat{w}} = 2 X^T(X \hat{w} - y) $$ 令上式等于0可以得到参数的最优解，但是由于涉及矩阵的逆，所以需要进行讨论。如果，$X^TX$是一个满秩矩阵或者正定矩阵，可以直接求： $$ \hat{w}^* = (X^TX)^{-1}X^Ty $$ 但现实任务往往不是满秩矩阵（没有一行或者一列为０），就会有多个解，这是需要使用正则化的方法。使用正则化技术，减少特征前面的参数w的大小，具体就是修改线性回归中的损失函数形式即可，岭回归以及Lasso回归就是这么做的。或者丢弃一些对我们最终预测结果影响不大的特征，具体哪些特征需要丢弃可以通过PCA算法来实现；</description>
    </item>
    
    <item>
      <title>[Review] Support Vector Machine</title>
      <link>https://kobehub.github.io/posts/review-support-vector-machine/</link>
      <pubDate>Mon, 14 Jan 2019 12:01:51 +0800</pubDate>
      
      <guid>https://kobehub.github.io/posts/review-support-vector-machine/</guid>
      <description>SVM 1. Margin and Support Vector 首先考虑一个线性分类任务,分类的最基本的想法就是在一个样本空间中划分一个超平面,将两个不同的类别的样本区分开。如何寻找超平面以及衡量超平面的好坏成为重要的问题。
为了正确的进行分类，我们需要找到一个鲁棒性更强的超平面，对于新的数据具有更强的泛化能力。在样本中，距离超平面的最近的样本点的距离应该尽可能的大，依据此规则选取超平面。
间隔:margin, 两类样本到划分超平面的最近的距离之和。代表着划分超平面对于样本局部扰动的”容忍性“，间隔越大，容忍性越好。
超平面可以用以下形式表示： $$ W^Tx+b = 0 $$ 根据超平面可以对样本进行划分： $$ \begin{cases} w^T x_i + b \ge 1, \qquad &amp;amp; y_i = +1 \\ w^Tx_i + b \le 1, \qquad &amp;amp; y_i = -1 \end{cases} $$ 支持向量： 距离超平面最小的训练样本使得等号成立，被称为支持向量
Margin: $\gamma = \frac{2}{||w||}$,
Target:最大化margin
为了找到具有最大间隔的超平面，使用以下目标函数： $$ \begin{align} &amp;amp; min_{w,b} \frac{1}{2} ||w||^2 \qquad (1) \\ &amp;amp; s.t. y_i(w^Tx_i+b) \ge 1, \qquad i=1,2,&amp;hellip;,m \end{align} $$ 这是支持向量机的基本模型。</description>
    </item>
    
    <item>
      <title>[Review] Decision Tree</title>
      <link>https://kobehub.github.io/posts/review-decision-tree/</link>
      <pubDate>Sun, 13 Jan 2019 21:05:17 +0800</pubDate>
      
      <guid>https://kobehub.github.io/posts/review-decision-tree/</guid>
      <description>Decision Tree 1. 决策树的定义以及建立 决策树是一种常见的机器学习方法。以二分类问题为例，决策树模拟人类处理问题的机制，对于某一个问题进行决策时，进行一些列的判断或者子决策。对于一棵决策树来说，具有以下属性：
 每一个非叶结点都是一个属性的划分 每一个划分指向下一个决策或者指向最终结论 决策过程从根结点开始，一直到叶结点 最终的结论对应一个目标值  基本决策树算法描述：
1. 选择一个最优属性对于剩余样本进行划分，并且将该属性作为一个结点2. 重复上述过程构造后代结点3. 遇到以下条件停止： 所有实例具有相同的值 在所有的属性集中，没有属性或者是实例具有相同的值 实例已全部划分 所以关于决策树的构建，最关键的问题在于最优属性的选取，不同的决策树算法实则是不同的属性选取方式
2. Information Gain 2.1 信息熵 随着划分的进行，我们希望决策树的分支结点所包含的样本尽可能属于同一个类别，即我们希望结点的“纯度”越来越高。信息熵（Information Entropy）可以作为纯度的一个度量标准，信息熵的计算方式：对于一个样本集合D中的第k类样本所占的比例为$p_k(k = 1,2,&amp;hellip;,|y|)$,则该样本集合的信息熵为： $$ Ent(D) = - \sum _{k=1}^{|y|}p_klog_2p_k $$ 信息熵越小，纯度越高。针对二分类问题，信息熵可以形式化为：$Entropy = -p_1log_2p_1-(1-p_1)log_2(1-p_1)$
当所有的样本属于同一个类别是，信息熵值为0.
2.2 信息增益 Information Gain可以表述为，一个通过对于一个属性的划分，原来样本集熵的下降情况。是一个属性的信息增益。所以对于一个属性而言，信息增益越大，说明使用该属性划分得到的纯度提升越大。
对于离散属性a，可能具有k个不同的取值${a^1, a^2,&amp;hellip;,a^k}$ ,所以对该属性进行划分会得到k个结点，将原样本集分为k个样本$D^1 &amp;hellip; D^k$
$$ Gain(D, a) = Ent(D) - \sum _{i=1}^k \frac{|D^i|}{|D|}Ent(D^i) $$ 有了信息增益，每次选取信息增益最大的属性进行划分。
2.3 信息增益率 信息增益准则对于可取值数目较多的属性有所偏好，如果把样本的编号作为一个属性添加进去，那么一个编号只有一个样本，“纯度”最高，所以会选取该属性进行样本的划分，但是这样的决策树显然不具有泛化能力，无法进行有效预测。
所以可以使用信息增益率作为最优属性的选择标准： $$ Gain\_ ratio(D, a) = \frac{Gain(D, a)}{IV(a)} \</description>
    </item>
    
    <item>
      <title>[Review] Bayesian decision theory</title>
      <link>https://kobehub.github.io/posts/review-bayesian-decision-theory/</link>
      <pubDate>Sun, 13 Jan 2019 17:11:19 +0800</pubDate>
      
      <guid>https://kobehub.github.io/posts/review-bayesian-decision-theory/</guid>
      <description>Bayesian decision theory 1. 常用的贝叶斯决策规则  基于最小错误率的贝叶斯决策 基于最小风险的贝叶斯决策 在限定一类错误率条件下使另一类错误率最小的两类别决策 最小最大决策  2.基本概率公式  条件概率：$p(A|B)$表示事件A在事件B发生的条件下发生的概率
 联合概率：$p(A. B)$ 表示两个事件同时发生的概率，当两个随机事件相互独立时，联合概率等于概率的乘积
  基本条件概率公式： $$ P(A | B) = \frac{P(A, B)}{P(B)} $$ 所以当A B相互独立时，$P(A|B) = P(A)$ .
 全概率公式： 如果B是由相互独立的事假组成的概率空间 ${B_1, B_2,&amp;hellip;,B_n}$, 那么关于事件A的全概率公式可以写作：  $$P(A) = \sum_{i=1}^{n}P(B_i)P(A|B_i)$$
对于全概率公式可以通过，条件概率进行推导，相当于将所有在B的子事件和同时A发生的概率的和，因为B的概率空间之和为1，所以最终得到的是A发生的概率。
 贝叶斯公式：   $$ P(B_i | A) = \frac{P(B_i)P(A|B_i)}{\sum _{i=1}^{n}P(B_i) P(A|B_i) } $$
其中 $P(B_i|A)$ 被称为后验概率，$P(B_i)$ 为先验概率，$P(A|B_i)$ 是条件概率
3. 基于最小错误率的贝叶斯决策 模式分类问题中，基于减少分类错误的要求。使用概率论中的贝叶斯公式，可得出使得分类错误率规则。
以简单的二分类任务为例，类别的状态用变量$w$表示，其中$w_1$表示正常，$w_2$表示异常。$p(w_1), p(w_2)$是已知的先验概率。那么有：</description>
    </item>
    
    <item>
      <title>[Review] Feature selection and feature extraction</title>
      <link>https://kobehub.github.io/posts/review-feature-selection-and-feature-extraction/</link>
      <pubDate>Sat, 12 Jan 2019 23:50:37 +0800</pubDate>
      
      <guid>https://kobehub.github.io/posts/review-feature-selection-and-feature-extraction/</guid>
      <description>特征选择与特征提取 1. 特征介绍 通常用于机器学习任务的特征集，可以使用一个 $l$ 维向量表示。称之为特征向量
$x = [x_1, x_2, &amp;hellip;, x_l]^T$
对于特征的产生，可以通过先验知识手工设定，也可以通过学习自动获取。对于先验知识较为明确，区分度大的样本，可以直接设计较好的特征将其分开；对于先验知识不明确，的特征集可以通学习获取。
继续以分类系统为例：针对一个典型的分类系统的基本步骤，有关特征工程（Feature Engineering）主要有两部分：
 特征产生 （feature generation）  特征设计 （design） 特征提取 （extraction）  特征选择  子集搜索 （subset search） 子集评估 （subset evaluation）   2. 特征选取 2.1 选取准则 选取与任务相关度最高的特征集，特征间相关性较低
特征与任务的相关性越大越好，特征间的相关性越小越好
2.2 特征选择的一般步骤  从原始的特征集出发对于子集进行搜索 对于特征子集进行评估 观察是否达到临界条件，达到即可以使用，否则继续上述操作  2.3 特征选取方法（ Relief / LVW / L1-Norm ） a. 过滤式（Filter）  在训练之前进行，与分类器无关。
 对数据集进行特征选取之后，根据一些评估方法，选出最优特征
 代表方法：relief。首先给定一个相关统计量（一种评估方法），可以将其理解为基于距离的，也可以是基于概率的评估。如果基于距离，如果只选取一个特征作为特征集，相当于把所有的数据放在一个一维的直线上，我们希望类内尽可能聚集，类间尽可能分离，也就是说希望 类间距离 与 类内距离 的比值尽可能大。可以计算该比值。
  现在可以设置一个阈值t 如果对于一个特征而言，经过评估其比值超过该阈值，就可以将该特征加入特征集。</description>
    </item>
    
    <item>
      <title>[Review] Main concept of ML</title>
      <link>https://kobehub.github.io/posts/review-main-concept-of-ml/</link>
      <pubDate>Sat, 12 Jan 2019 17:43:29 +0800</pubDate>
      
      <guid>https://kobehub.github.io/posts/review-main-concept-of-ml/</guid>
      <description>机器学习的一些重要概念 1. 机器学习系统的主要操作 对于一个基于普通机器学习方法的分类系统，可能具有以下的基本操作步骤：
 数据收集(Sensing)
 数据预处理(Preprocessing):
  通常使用分割操作，将分类目标与背景进行分离
 特征定义以及特征提取(Feature definition and Extraction)  以上过程一般都需要使用到一定的先验知识(Prior Knowledge)
 选取模型(Model Selection)
 训练(Training)
 模型评估(Evaluation)
  2.机器学习的主要任务 有标记数据的分类(Classification)以及回归(Regression)，无标记数据进行聚簇分析(Clustering Analysis),异常检测(Anomaly Detection).
1. 学习器  K-Nearest Neighbor(K-NN)  在特征空间找到K个最近的邻居，选取数量最大的类别作为某个样本的预测类别。无需训练，适用于小数据量，非线性问题
 Decision Tree  通过每次选取最优特征进行进一步决策，构成了一组规则集组成的决策树，通过输入样本的特征进行分类任务。
决策过程具有良好的可理解性，对于单一因素即可决定的预测结果的问题，可以弥补基于统计的机器学习的不足。
 Support Vector Machine  在特征空间选取一个超平面，使得所有样本点到超平面的总距离最小。通过定义一个间隔(Margin),最大化Margin，选取一个合适的超平面用于分类任务。通过使用合适的变换核可以进行解决非线性问题。
在解决小规模、非线性问题上具有优势，因为对于预测起到决定性作用的，是少数边界上的向量(Support Vector)
 朴素贝叶斯(Naive Bayesian)
 Neural Networks
 最小二乘 (Least Squares)
 高斯混合模型（Gaussian Mixture Model）
 Hidden Markov Model</description>
    </item>
    
  </channel>
</rss>